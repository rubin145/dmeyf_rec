{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ganancia_total_eval_nativa\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "#import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "from ...utils import ganancia_total_eval_nativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../data_proceso/X_train.npy',allow_pickle=True)\n",
    "y_train = np.load('../data_proceso/y_train.npy')\n",
    "feature_names = list(np.load('../data_proceso/feature_names.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"binary_logloss\",\n",
    "            early_stopping_rounds=100,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, \"binary_logloss\")\n",
    "            ],  # Add a pruning callback\n",
    "        )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    param = {\n",
    "        'objective': 'l1',\n",
    "        'metric': 'l1',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',        \n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 2, 256),\n",
    "        'seed': 1979\n",
    "    }\n",
    "       \n",
    "    # insert code for getting X and y ready \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    lcv = lgb.cv(\n",
    "        param, \n",
    "        dtrain, \n",
    "        verbose_eval=False)\n",
    "                \n",
    "    return lcv['l1-mean'][-1]+lcv['l1-stdv'][-1]\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 04:17:40,468]\u001b[0m A new study created in memory with name: no-name-c50585a6-7025-497b-9080-a95f0e11ddcd\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'ganancia',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt'\n",
    "}\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, label=y_train,feature_name=feature_names)\n",
    "\n",
    "tuner = lgb.LightGBMTunerCV(param,dtrain,time_budget=180,feval=ganancia_total_eval_nativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[32m[I 2023-02-10 04:23:19,703]\u001b[0m Trial 0 finished with value: 40608400.0 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 40608400.0.\u001b[0m\n",
      "feature_fraction, val_score: 40608400.000000:  14%|#4        | 1/7 [05:37<33:42, 337.05s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ask',\n",
       " '_directions',\n",
       " '_is_multi_objective',\n",
       " '_log_completed_trial',\n",
       " '_pop_waiting_trial_id',\n",
       " '_should_skip_enqueue',\n",
       " '_stop_flag',\n",
       " '_storage',\n",
       " '_study_id',\n",
       " '_tell',\n",
       " '_thread_local',\n",
       " 'add_trial',\n",
       " 'add_trials',\n",
       " 'ask',\n",
       " 'best_params',\n",
       " 'best_trial',\n",
       " 'best_trials',\n",
       " 'best_value',\n",
       " 'direction',\n",
       " 'directions',\n",
       " 'enqueue_trial',\n",
       " 'get_trials',\n",
       " 'optimize',\n",
       " 'pruner',\n",
       " 'sampler',\n",
       " 'set_system_attr',\n",
       " 'set_user_attr',\n",
       " 'stop',\n",
       " 'study_name',\n",
       " 'system_attrs',\n",
       " 'tell',\n",
       " 'trials',\n",
       " 'trials_dataframe',\n",
       " 'user_attrs']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tuner.study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Study.ask of <optuna.study.study.Study object at 0x7f1d6e3cfa00>>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.study.ask"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83f819a7c7b4b04da698bb686dbfa0aeaa192108f30ae9d3cf384d70516a554d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dmeyf-kP6Zbi_a')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
