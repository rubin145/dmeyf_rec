{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from utils import g_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_function(leaf_size_log, coverage, learning_rate, feature_fraction):\n",
    "    full_params = {**params_fijos,'learning_rate':learning_rate, 'feature_fraction':feature_fraction}\n",
    "    full_params['min_data_in_leaf'] = np.maximum(1, np.around(X_train.shape[0] / (2.0 ** leaf_size_log)).astype(int))\n",
    "    full_params['num_leaves']  =  np.minimum(131072, np.maximum(2, np.around(coverage * X_train.shape[0] / full_params['min_data_in_leaf']).astype(int)))\n",
    "    #que carajo es 131072\n",
    "    #del params['leaf_size_log']\n",
    "    #del params['coverage']\n",
    "    #full_params = {**params,**params_fijos}\n",
    "    model = lgb.LGBMClassifier(**full_params)\n",
    "    return cross_val_score(model, X_train, y_train, scoring=g_score, cv=cv, n_jobs=-1).mean()\n",
    "    #acá se pierde la varianza de los scores pero bueno..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy',allow_pickle=True)\n",
    "y_train = np.load('y_train.npy')\n",
    "feature_names = list(np.load('feature_names.npy'))\n",
    "cv = KFold() #ver si hay que usar shuffle o no (sólo ahí random_state.) n_splits = default 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_fijos = {\n",
    "   'boosting': \"gbdt\",               #puede ir  dart  , ni pruebe random_forest\n",
    "   'objective': \"binary\",\n",
    "   'metric': \"custom\",\n",
    "   'first_metric_only': True,\n",
    "   'boost_from_average': True,\n",
    "   'feature_pre_filter': False,\n",
    "   'force_row_wise': True,           #para que los alumnos no se atemoricen con tantos warning\n",
    "   'verbosity': -100,\n",
    "   'max_depth':  -1,                 # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "   'min_gain_to_split': 0.0,         #por ahora, lo dejo fijo\n",
    "   'min_sum_hessian_in_leaf': 0.001, #por ahora, lo dejo fijo\n",
    "   'lambda_l1': 0.0,                 #por ahora, lo dejo fijo\n",
    "   'lambda_l2': 0.0,                 #por ahora, lo dejo fijo\n",
    "   'max_bin': 31,                    #por ahora, lo dejo fijo\n",
    "   'num_iterations': 9999,           #un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "   'bagging_fraction': 1.0,          #por ahora, lo dejo fijo\n",
    "   'pos_bagging_fraction': 1.0,      #por ahora, lo dejo fijo\n",
    "   'neg_bagging_fraction': 1.0,      #por ahora, lo dejo fijo\n",
    "\n",
    "   'drop_rate':  0.1,                #solo se activa en  dart\n",
    "   'max_drop': 50,                   #solo se activa en  dart\n",
    "   'skip_drop': 0.5,                 #solo se activa en  dart\n",
    "\n",
    "   'extra_trees': False,\n",
    "\n",
    "   'seed': 1\n",
    "}\n",
    "\n",
    "pbounds = { \n",
    "         \"learning_rate\":       (0.01,  0.3),\n",
    "         \"feature_fraction\":    (0.2,   0.8),\n",
    "         \"coverage\":            (0.05,  1.0),\n",
    "         \"leaf_size_log\":       (1.0,   12.0)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=black_box_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# optimizer.probe(\n",
    "#     params={\"x\": 0.5, \"y\": 0.7},\n",
    "#     lazy=True,\n",
    "# )\n",
    "\n",
    "logger = JSONLogger(path=\"./logs.json\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6321946960652949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321946960652949\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41963, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41963\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6321946960652949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321946960652949\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41963, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41963\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6321946960652949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321946960652949\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41963, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41963\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6321946960652949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321946960652949\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41963, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41963\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6321946960652949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6321946960652949\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=41963, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=41963\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2554031568612787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2554031568612787\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10150\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2554031568612787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2554031568612787\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10150\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2554031568612787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2554031568612787\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10150\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2554031568612787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2554031568612787\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10150\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2554031568612787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2554031568612787\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10150\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.29711656052761776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29711656052761776\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.29711656052761776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29711656052761776\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.29711656052761776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29711656052761776\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.29711656052761776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29711656052761776\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.29711656052761776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.29711656052761776\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=188, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.44808242476044025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44808242476044025\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=645, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=645\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.44808242476044025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44808242476044025\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=645, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=645\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.44808242476044025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44808242476044025\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=645, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=645\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.44808242476044025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.44808242476044025\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=645, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=645\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:311\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=308'>309</a>\u001b[0m     x_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuggest(util)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=309'>310</a>\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=310'>311</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobe(x_probe, lazy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=312'>313</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer \u001b[39mand\u001b[39;00m iteration \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=313'>314</a>\u001b[0m     \u001b[39m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=314'>315</a>\u001b[0m     \u001b[39m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=315'>316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_bounds(\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=316'>317</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queue\u001b[39m.\u001b[39madd(params)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=206'>207</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=207'>208</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_space\u001b[39m.\u001b[39;49mprobe(params)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py?line=208'>209</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(Events\u001b[39m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/target_space.py?line=233'>234</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_as_array(params)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/target_space.py?line=234'>235</a>\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keys, x))\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/target_space.py?line=235'>236</a>\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/target_space.py?line=237'>238</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constraint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/bayes_opt/target_space.py?line=238'>239</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mblack_box_function\u001b[0;34m(leaf_size_log, coverage, learning_rate, feature_fraction)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#que carajo es 131072\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#del params['leaf_size_log']\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#del params['coverage']\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#full_params = {**params,**params_fijos}\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_params)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=511'>512</a>\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=512'>513</a>\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=514'>515</a>\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=515'>516</a>\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=516'>517</a>\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=517'>518</a>\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=518'>519</a>\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=519'>520</a>\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=520'>521</a>\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=521'>522</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=522'>523</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=523'>524</a>\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=524'>525</a>\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=525'>526</a>\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=526'>527</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=527'>528</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=262'>263</a>\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=263'>264</a>\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=264'>265</a>\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=265'>266</a>\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=266'>267</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=267'>268</a>\u001b[0m         clone(estimator),\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=268'>269</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=269'>270</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=270'>271</a>\u001b[0m         scorers,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=271'>272</a>\u001b[0m         train,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=272'>273</a>\u001b[0m         test,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=273'>274</a>\u001b[0m         verbose,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=274'>275</a>\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=275'>276</a>\u001b[0m         fit_params,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=276'>277</a>\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=277'>278</a>\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=278'>279</a>\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=279'>280</a>\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=280'>281</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=281'>282</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=282'>283</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=284'>285</a>\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=286'>287</a>\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=287'>288</a>\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py?line=288'>289</a>\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py?line=57'>58</a>\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py?line=58'>59</a>\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py?line=59'>60</a>\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py?line=60'>61</a>\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py?line=61'>62</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/sklearn/utils/parallel.py?line=62'>63</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=1094'>1095</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=1096'>1097</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=1097'>1098</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=1098'>1099</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=1099'>1100</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=972'>973</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=973'>974</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=974'>975</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=975'>976</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/parallel.py?line=976'>977</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=563'>564</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=564'>565</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=565'>566</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=566'>567</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=567'>568</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/user/.local/share/virtualenvs/dmeyf-kP6Zbi_a/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=435'>436</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=436'>437</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=438'>439</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=440'>441</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/threading.py?line=299'>300</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/threading.py?line=300'>301</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/threading.py?line=301'>302</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/threading.py?line=302'>303</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/threading.py?line=303'>304</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_optimizer = BayesianOptimization(\n",
    "#     f=black_box_function,\n",
    "#     pbounds={\"x\": (-2, 2), \"y\": (-2, 2)},\n",
    "#     verbose=2,\n",
    "#     random_state=7,\n",
    "# )\n",
    "# load_logs(optimizer, logs=[\"./logs.json\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.0,\n",
       "  'params': {'coverage': 0.4461709044674453,\n",
       "   'feature_fraction': 0.6321946960652949,\n",
       "   'leaf_size_log': 1.0012581229907938,\n",
       "   'learning_rate': 0.09767644606323352}},\n",
       " {'target': 32773200.0,\n",
       "  'params': {'coverage': 0.18941809627625739,\n",
       "   'feature_fraction': 0.2554031568612787,\n",
       "   'leaf_size_log': 3.04886232515438,\n",
       "   'learning_rate': 0.11021261084248384}},\n",
       " {'target': 41316400.0,\n",
       "  'params': {'coverage': 0.05733386318491501,\n",
       "   'feature_fraction': 0.29711656052761776,\n",
       "   'leaf_size_log': 8.803059375869982,\n",
       "   'learning_rate': 0.23177368910756427}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.res"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83f819a7c7b4b04da698bb686dbfa0aeaa192108f30ae9d3cf384d70516a554d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dmeyf-kP6Zbi_a')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
